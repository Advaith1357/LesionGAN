# -*- coding: utf-8 -*-
"""URes Copy of GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XEPpljLMdF63tzX-Ue2QX7a2_ZKZ_L_b
"""

from google.colab import drive
drive.mount('/content/drive')

from dagan_gen_orig_way import UResNetGenerator
from dagan_disc_orig_way import Discriminator

PATH = "/content/drive/Shareddrives/1:1 Advaith Menon/Downloads/final_datasets/Vanilla_Dataset/"
#PATH= "C:\\Users\\advai\\Downloads\\ProcessedImages\\ProcessedImages\\"
#in_path = "/content/drive/Shareddrives/1:1 Advaith Menon/Downloads/processed-nihcc/1/"

from keras.applications.resnet import preprocess_input
from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator()

BATCH_SIZE = 4

img_size = 64
IMG_SIZE = (img_size,img_size)

train_generator = train_datagen.flow_from_directory(PATH,
                                                target_size=IMG_SIZE,
                                                color_mode='rgb',
                                                batch_size=BATCH_SIZE,
                                                class_mode='categorical',
                                                shuffle=True)

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf
from tensorflow.keras import layers
import time

from IPython import display

def make_generator_model():
    model = UResNetGenerator(image_size = img_size, batch_size=BATCH_SIZE, dropout = 0.3, layer_sizes=[64, 64, 128, 128],
                                  num_channels=3, layer_padding=["SAME", "SAME", "SAME", "SAME"],
                                  inner_layers=3).model
    return model

def make_discriminator_model():
    model = Discriminator(image_size= img_size,batch_size=BATCH_SIZE,layer_sizes=[128, 128, 128, 128],num_channels=3,inner_layers=5).model
    return model

generator = make_generator_model()
discriminator = make_discriminator_model()
discriminator.summary()
generator.summary()

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

EPOCHS = 100
noise_dim = 500
num_examples_to_generate = 32

# You will reuse this seed overtime (so it's easier)
# to visualize progress in the animated GIF)
seed = tf.random.normal([num_examples_to_generate, noise_dim])

# Notice the use of `tf.function`
# This annotation causes the function to be "compiled".

def train_step(images, n,train_discriminator):
    z_input = tf.convert_to_tensor(tf.random.normal([BATCH_SIZE, 100], mean=0, stddev=1.0))

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      if train_discriminator:
        generated_images = generator([images[0],z_input], training=False)
        real_output = discriminator(images[0], training=True)
        fake_output = discriminator(generated_images, training=True)
      else:
        generated_images = generator([images[0],z_input], training=True)
        real_output = discriminator(images[0], training=False)
        fake_output = discriminator(generated_images, training=False)

      gen_loss = generator_loss(fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)
      print("finished train step " + str(n))
    if train_discriminator:
      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
    else:
      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)

def train(dataset, epochs):
  n=0
  for epoch in range(epochs):
    start = time.time()
    count = 0
    for image_batch in dataset:
      count = count + 1
      train_discriminator = True
      if (count)%300 == 0:
        train_discriminator = False
      train_step(image_batch, n,train_discriminator)
      n+=1
      display.clear_output(wait=True)

      generate_and_save_images(generator,
                              epoch + 1,
                              image_batch[0])


    # Produce images for the GIF as you go


      if (count)%10 == 0:
        checkpoint.save(file_prefix = checkpoint_prefix)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # Generate after the final epoch
  display.clear_output(wait=True)
  generate_and_save_images(generator,
                        epochs,
                           image_batch[0])

def generate_and_save_images(model, epoch, test_input):
  # Notice `training` is set to False.
  # This is so all layers run in inference mode (batchnorm).
  z_input = tf.convert_to_tensor(tf.random.normal([BATCH_SIZE, 100], mean=0, stddev=1.0))
  predictions = model([test_input,z_input], training=False)

  fig = plt.figure(figsize=(4, 4))

  for i in range(predictions.shape[0]):
      plt.subplot(4, 4, i+1)
      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
      plt.axis('off')

  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
  plt.show()

checkpoint_dir = '/content/drive/Shareddrives/1:1 Advaith Menon/Downloads/training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

train(train_generator, EPOCHS)

#Generating Images3